{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer_vision_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2ch_YS0evyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b7e91a-e9da-4c46-a8e1-b8150717bcbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.measure as sime"
      ],
      "metadata": {
        "id": "pgWxysZ4feAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im = cv2.imread('/content/drive/MyDrive/obrazy/projekt/elementy1_1.tif')"
      ],
      "metadata": {
        "id": "lOT08460lTUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split image to channels\n",
        "\n",
        "imageChannels = cv2.split(im)\n",
        "\n",
        "# thresholding channels\n",
        "for i in range(0, 3):\n",
        "    _, imageChannels[i] = cv2.threshold(imageChannels[i], 60, 255, cv2.THRESH_BINARY)\n",
        "    imageChannels[i] = np.reshape(\n",
        "        imageChannels[i], newshape=(imageChannels[0].shape[0], imageChannels[0].shape[1], 1))\n",
        "\n",
        "# concatenate channels\n",
        "image = np.concatenate((imageChannels[0], imageChannels[1], imageChannels[2]), axis=2)\n",
        "\n",
        "# OTSU threshold - for binary image as a reference\n",
        "_, binaryImage = cv2.threshold(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), 0, 255, cv2.THRESH_OTSU)\n"
      ],
      "metadata": {
        "id": "_xbw1lr-lOVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binaryImage = ~binaryImage\n",
        "\n",
        "# labelling\n",
        "labels = sime.label(binaryImage)\n",
        "\n",
        "# feature extraction\n",
        "features = sime.regionprops(labels)\n",
        "\n",
        "# counting colors\n",
        "colors = np.unique(image.reshape(-1, image.shape[2]), axis=0) # colors in the image\n",
        "\n",
        "colors[1,:] = colors[2,:]\n",
        "colors[2,:] = colors[3,:]\n",
        "\n",
        "bboxCoordinates = []\n",
        "objectsNumber = len(features)\n",
        "categoriesNumber = len(colors)\n",
        "featuresList = ['EulerNumber', 'Area']\n",
        "featuresNumber = len(featuresList)\n",
        "featuresTable = np.zeros((objectsNumber, featuresNumber + 1))\n",
        "featuresTable[0,:] = np.nan # features nonexistent object with label \"0\"\n",
        "\n",
        "for i in range(objectsNumber):\n",
        "    for j in range(featuresNumber):\n",
        "      featuresTable[i,j] = features[i][featuresList[j]]\n",
        "    # color sampling - taking one pixel from each object\n",
        "    x, y = features[i]['Coordinates'][1] \n",
        "    for k in range(categoriesNumber):\n",
        "        if list(image[x,y,:]) == list(colors[k, :]):\n",
        "            break;\n",
        "    featuresTable[i,-1] = k\n",
        "    bboxCoordinates.append(features[i]['BoundingBox'])"
      ],
      "metadata": {
        "id": "68-s4itAR0o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if object is touching edge\n",
        "\n",
        "def isNotOnEdge(coordinatesList, imageShape):\n",
        "  notOnEdgeList = []\n",
        "  for coordinates in coordinatesList:\n",
        "    if coordinates[0] == 0 or coordinates[1] == 0 or coordinates[2] == imageShape[0] or coordinates[3] == imageShape[1]:\n",
        "      notOnEdgeList.append(False)\n",
        "    else:\n",
        "      notOnEdgeList.append(True) \n",
        "  return notOnEdgeList"
      ],
      "metadata": {
        "id": "kbT2BNyvsd81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all criteria\n",
        "\n",
        "notOnEdge = np.where(isNotOnEdge(bboxCoordinates, image.shape))\n",
        "areaOfSurfaceGroundTruth = 2100\n",
        "\n",
        "for i in range(3):\n",
        "  colorName = \"green\" if i == 0 else \"blue\" if i == 1 else \"pink\"\n",
        "  color = np.where(featuresTable[:,-1] == i)\n",
        "  imageInColor = np.where(np.isin(labels, color + np.array(1)), 255, 0)\n",
        "\n",
        "  correctAreaOfSurface = np.where(featuresTable[:,1]  > areaOfSurfaceGroundTruth) \n",
        "  euler0 = np.where(featuresTable[:,0] == 0)   \n",
        "\n",
        "  buffer1 = np.intersect1d(notOnEdge, color)\n",
        "  buffer2 = np.intersect1d(buffer1, correctAreaOfSurface)\n",
        "  buffer3 = np.intersect1d(buffer2, euler0)\n",
        "\n",
        "  info = \"Color {} \\n\"\n",
        "  print(info.format(colorName))\n",
        "  print(\"---------------------------------------------\")\n",
        "  print(\"Number of items matching the criteria:\", buffer3.size)\n",
        "  print(\"Number of items not matching the criteria:\", buffer1.size - buffer3.size)\n",
        "  print(\"---------------------------------------------\\n\")\n"
      ],
      "metadata": {
        "id": "fCn9v7s3XEiL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}